{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook & Python Demo\n",
    "\n",
    "- This Notebook file can be run directly on your laptop\n",
    "- Method 1: Launch Anaconda Navigator, click Jupyter Notebook icon\n",
    "- Method 2: In a command-line environment, `cd` (change directory) into the workshop repo, then type in `jupyter notebook`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting around in Jupyter Notebook\n",
    "\n",
    "- Click `+` to create a new cell, â–º to run (Also: `Ctrl+ENTER`)\n",
    "- Choose appropriate cell type (Code or Markdown)\n",
    "- `Alt+ENTER` to run cell, create a new cell below\n",
    "- `Shift+ENTER` to run cell, go to next cell\n",
    "- More on [this page](https://www.cheatography.com/weidadeyue/cheat-sheets/jupyter-notebook/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Hello, world!')    # printing a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Hello, world!'           # returning a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len('Hello, world!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.word_tokenize('Hello, world!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = nltk.word_tokenize('Hello, world!')\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"You haven't seen Star Wars...?\"\n",
    "nltk.word_tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of speakers in million\n",
    "plt.bar(['Zulu', 'German', 'Polish'], [10, 100, 45])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Jupyter Notebook\n",
    "JNB lets us weave together 4 essential components into a single document: \n",
    "  1. Python code\n",
    "  2. code output (`print`, returned values, etc.)\n",
    "  3. visualization through in-line plots\n",
    "  4. narration and documentation as Markdown cells\n",
    "\n",
    "\n",
    "Additionally, it is good practice to make a point of **showing the \"data\"**:\n",
    "  5. Data itself: snippets, examples\n",
    "  6. The process in which data gets cleaned and transformed\n",
    "\n",
    "#### Benefits\n",
    "- The resulting Notebook document presents a **complete picture of \"code as research\"**\n",
    "- The Notebook document is live code that can be run by anyone: easy **reproducibility**\n",
    "- **Sharability**: [GitHub](https://www.github.com) and other online platforms not only hosts but renders Notebook documents in easily readable and browsable form  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the Gettysburg Address\n",
    "- Let's process Abraham Lincoln's Gettysburg address, already in the `data` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfile = 'data/1863-Gettysburg Address.txt'\n",
    "gtxt = open(gfile).read()\n",
    "gtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gtxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gtxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JNB by default has \"pretty printing\" turned on, which prints list items in separate lines. \n",
    "# Toggle it off. \n",
    "%pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type vs. token, TTR\n",
    "- *Tokens* are individual instances of linguistic units. \n",
    "- *Types* are unique classes found in the tokens. \n",
    "- *TTR* (\"type-token ratio\") is a measure of vocabulary richness (with a huge caveat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtoks = nltk.word_tokenize(gtxt)\n",
    "gtoks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gtoks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list comprehension: returns a new list where each item is transformed\n",
    "gtypes = set([w.lower() for w in gtoks])  \n",
    "gtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gttr = len(gtypes)/len(gtoks)\n",
    "gttr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average sentence length\n",
    "- NLTK has a handy sentence tokenizer: `nltk.sent_tokenize()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence tokenization\n",
    "nltk.sent_tokenize(\"Hello, world! I come in peace.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsents = nltk.sent_tokenize(gtxt)\n",
    "gsents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsents[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gsents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average sentence length\n",
    "gsentlen = len(gtoks)/len(gsents)\n",
    "gsentlen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word frequency \n",
    "- `nltk.FreqDist()` builds a frequency distribution. Pass tokenized words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfd = nltk.FreqDist(gtoks)\n",
    "gfd.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfd.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfd['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relative frequency\n",
    "gfd.freq('the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = ['that', 'the', 'to', 'we', 'here', 'a', 'and', 'nation', 'of']\n",
    "top_gfreq = [gfd.freq(w) for w in top_words]\n",
    "top_gfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(top_words, top_gfreq)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary: the Gettysburg Address \n",
    "- 309 word tokens and 141 word types\n",
    "- TTR: 0.4563\n",
    "- 10 sentences\n",
    "- Average sentence length: 30.9 words per sentence\n",
    "- Top words include 'that', 'the', 'to', 'we', 'here', 'a', etc. \n",
    "\n",
    "NB: punctuation and symbols were included in the token count and the average sentence length. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your turn: \"I Have A Dream\" by Martin Luther King Jr. \n",
    "- Longer or shorter than \"Gettysburg address\"?\n",
    "- TTR?\n",
    "- Average sentence length: longer or shorter?\n",
    "- Top words and their frequencies: difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfile = 'data/1963-I Have a Dream.txt'\n",
    "ktxt = open(kfile).read()\n",
    "ktxt[:500]  # first 500 characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ktxt[-500:]  # last 500 characters  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) build a list of word tokens\n",
    "# (2) build a set of word types\n",
    "#   from (1) & (2), compute TTR\n",
    "# (3) build a list of tokenized sentences\n",
    "#   from (1) and (3), compute average sentence length\n",
    "# (4) build a word frequency distribution, from (1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'b-': blue line\n",
    "# build top_kfreq first! \n",
    "plt.plot(top_words, top_gfreq, 'b-', top_words, top_kfreq, 'g-')\n",
    "plt.title('word types and frequencies')\n",
    "plt.xlabel('Lincoln (blue) vs. King (green)') \n",
    "plt.ylabel('relative frequency')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
